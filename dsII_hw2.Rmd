---
title: "Data Science II: HW2" 
author: "Shayne Estill"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r}
library(caret)
library(tidymodels)
library(kknn)
library(FNN) # knn.reg()
library(doBy) # which.minn()
library(tidyverse)
library(glmnet)
library(ISLR)
library(pls)
library(splines)
library(mgcv)
library(pdp)
library(earth)
library(ggplot2)
library(bayesQR)
```


Partition the dataset into two parts: training data (80%) and test data (20%).
(a) Fit smoothing spline models to predict out-of-state tuition (Outstate) using the percentage
of alumni who donate (perc.alumni) as the only predictor, across a range of degrees of
freedom. Plot the fitted curve for each degree of freedom. Describe the patterns you observe
as the degrees of freedom change. Choose an appropriate degree of freedom for the model
and plot this optimal fit. Explain the criteria you used to select the degree of freedom.
```{r}
college_data = read_csv(file = "/Users/shayneestill/Desktop/Data Science II/dsII_hw2/College.csv", 
                        na = c("NA", ".", "")) |>
                        janitor::clean_names()
drop_na(college_data)
set.seed(1)

data_split <- initial_split(college_data, prop = 0.8)

# Extract the training and test data
training_data <- training(data_split)
testing_data <- testing(data_split)

# training data
x <- model.matrix(outstate ~ perc_alumni, training_data)[, -1]
y <- training_data$outstate

# test data
x2 <- model.matrix(outstate ~ perc_alumni,testing_data)[, -1]
y2 <- testing_data$outstate
```

```{r}
summary(college_data$perc_alumni)
```


```{r}
fit.ss <- smooth.spline(training_data$perc_alumni, training_data$outstate)
fit.ss$df

perc_alumni.grid <- seq(from = 0, to = 65, by = 1)

p <- ggplot(data = training_data, aes(x = perc_alumni, y = outstate)) +
geom_point(color = rgb(.2, .4, .2, .5))

pred.ss <- predict(fit.ss, x = perc_alumni.grid)

pred.ss.df <- data.frame(pred = pred.ss$y,
              perc_alumni = perc_alumni.grid)
p + geom_line(aes(x = perc_alumni, y = pred), data = pred.ss.df,
color = rgb(.8, .1, .1, 1)) + theme_bw()
```

```{r}
df_values <- c(2, 5, 10, 15)  

for (df in df_values) {
  fit.ss <- smooth.spline(training_data$perc_alumni, training_data$outstate, df = df)
  pred.ss <- predict(fit.ss, x = perc_alumni.grid)
  pred.ss.df <- data.frame(pred = pred.ss$y, perc_alumni = perc_alumni.grid)
  
  p <- p + geom_line(data = pred.ss.df, aes(x = perc_alumni, y = pred, color = df))
}
```


```{r}
df_values <- c(2, 5, 10, 15)
pred_list <- list()  # Create an empty list to store data

for (df in df_values) {
  fit.ss <- smooth.spline(training_data$perc_alumni, training_data$outstate, df = df)
  pred.ss <- predict(fit.ss, x = perc_alumni.grid)
  
  # Store predictions in a dataframe with df as a factor
  pred_list[[as.character(df)]] <- data.frame(
    perc_alumni = perc_alumni.grid,
    pred = pred.ss$y,
    df = as.factor(df)  # Convert df to a factor for discrete color mapping
  )
}

# Combine all predictions into one dataframe
predictions_df <- do.call(rbind, pred_list)

# Base scatterplot
p <- ggplot(training_data, aes(x = perc_alumni, y = outstate)) +
  geom_point(color = rgb(.2, .4, .2, .5)) +
  theme_bw()

# Add smoothing spline lines with color mapped to df
p + geom_line(data = predictions_df, aes(x = perc_alumni, y = pred, color = df), size = 1) +
  scale_color_manual(values = c("red", "green", "purple", "orange")) +
  labs(color = "Degrees of Freedom") +
  ggtitle("Smoothing Spline Fits with Different Degrees of Freedom")

```

As the degrees of freedom increase, the line gets more squiggly and less smooth. 
I would choose degree of freedom 2 because it is the most parsimonious. Fit.ss is
using cross validation to get 2. 





(b) Train a multivariate adaptive regression spline (MARS) model to predict the response
variable. Report the regression function. Present the partial dependence plot of an arbitrary predictor in your model. Report the test error.

```{r}
mars_grid <- expand.grid(degree = 1:3, nprune = 2:16)

ctrl1 <- trainControl(method = "cv", number = 10)

set.seed(2)

mars.fit <- train(model.matrix(outstate ~ ., training_data)[, -c(1,9)], training_data$outstate,
method = "earth",
tuneGrid = mars_grid,
trControl = ctrl1)
ggplot(mars.fit)
```


```{r}
mars.fit$bestTune
```

```{r}
coef(mars.fit$finalModel)
```

The regression function is 12623.8352 + 184.5414x1 - 129.9566x2 
```{r}
p1 <- pdp::partial(mars.fit, pred.var = c("perc_alumni"), grid.resolution = 10) |> autoplot()

p2 <- pdp::partial(mars.fit, pred.var = c("ph_d", "apps"),
grid.resolution = 10) |>
pdp::plotPartial(levelplot = FALSE, zlab = "yhat", drape = TRUE,
screen = list(z = 20, x = -60))

gridExtra::grid.arrange(p1, p2, ncol = 2)
```

```{r}
mars_grid <- expand.grid(degree = 1:3, nprune = 2:16)

mars.fit <- train(model.matrix(outstate ~ ., training_data)[, -c(1,9)], training_data$outstate,
method = "earth",
tuneGrid = mars_grid,
trControl = ctrl1)
ggplot(mars.fit)
```


(c) Construct a generalized additive model (GAM) to predict the response variable. For the
nonlinear terms included in your model, generate plots to visualize these relationships and
discuss your observations. Report the test error.
```{r}
gam.m1 <- gam(outstate ~ s(perc_alumni)+ s(apps) + s(accept) + s(enroll) +
                s(top10perc) + s(top25perc) + s(f_undergrad) + s(p_undergrad) +
                s(room_board) + s(books) + s(personal) + s(ph_d) + s(terminal) +
                s(s_f_ratio) + s(perc_alumni) + s(expend) + s(grad_rate),
              data = training_data)

par(mfrow=c(1,2))
plot(gam.m1)

rmse <- sqrt(mean((test_data$y - predictions)^2))
print(paste("Test RMSE:", rmse))
```



(d) In this dataset, would you favor a MARS model over a linear model for predicting out-of-
state tuition? If so, why? More broadly, in general applications, do you consider a MARS
model to be superior to a linear model? Please share your reasoning.


I would favor MARS over a linear model over for predicting out of state tuition because MARS
is more flexible and adaptive than a linear model. However, we do loose out on interpretability of 
the prediction. 







